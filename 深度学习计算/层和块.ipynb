{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25877176-a98f-4fae-b071-21dc91312352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0032,  0.0834, -0.0034, -0.2626, -0.0503, -0.0578,  0.0086, -0.0337,\n",
       "         -0.1709, -0.1051],\n",
       "        [ 0.0037,  0.0686, -0.0685, -0.2429,  0.1034,  0.0119, -0.0229, -0.0502,\n",
       "         -0.1360, -0.1005]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff699ce-3c8f-427f-ba4a-a40c1d236325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义块\n",
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a4542c-4499-44c4-9088-b9782b1e5078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0479, -0.0242,  0.0766,  0.0971, -0.1785,  0.0473, -0.0398,  0.0629,\n",
       "         -0.0871, -0.0596],\n",
       "        [-0.0606, -0.0723,  0.0723,  0.0504, -0.1300,  0.0064, -0.0734,  0.1659,\n",
       "          0.0075, -0.0443]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e5e38a-fef0-4c70-9bf5-f3f13c4645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义层\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78e073e-dc64-4cc9-909d-e7e7a2e3f565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84b63a6-c967-4012-9d97-61f27de3d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5811361c-a49e-4a47-912f-eec98cc753ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7996e-01, -1.0267e-02,  9.5267e-02, -1.2180e-01, -3.4127e-01,\n",
      "         -3.3285e-02, -2.6685e-01, -1.1380e-01,  6.5338e-02,  6.0799e-01,\n",
      "          2.0657e-01, -1.5468e-01, -6.6768e-01, -3.4184e-01, -1.6016e-01,\n",
      "          6.5295e-01, -2.1268e-01, -2.3454e-01,  7.1847e-01, -6.0652e-01,\n",
      "         -2.4792e-01, -2.6870e-01, -2.7777e-01, -6.7275e-01, -1.1908e-01,\n",
      "          2.8163e-01,  7.2165e-01, -2.7291e-01,  1.0706e-01, -2.7330e-01,\n",
      "         -1.8959e-01, -3.1010e-02, -2.3547e-01, -4.2721e-02, -7.2180e-01,\n",
      "          3.4551e-01, -3.4373e-01,  4.5221e-01, -3.6326e-01,  5.3282e-02,\n",
      "         -2.2542e-01, -7.7740e-03, -4.9194e-01, -3.9410e-01,  5.2417e-01,\n",
      "          9.8395e-02,  1.2157e-01, -4.1852e-01,  1.4671e-03,  7.5132e-02,\n",
      "         -4.5669e-01,  4.1758e-02,  1.1511e-01, -3.0402e-02,  5.0816e-01,\n",
      "          4.0541e-01,  2.3780e-01, -4.0328e-01,  1.5919e-02, -2.5492e-01,\n",
      "         -5.1630e-01, -1.4718e-02, -1.9579e-01, -5.1256e-01, -2.5013e-01,\n",
      "         -1.4192e-02, -2.4486e-01, -8.5989e-01,  7.0570e-01,  3.9044e-01,\n",
      "         -5.4412e-01, -1.8650e-02,  7.4355e-01, -2.5087e-01,  4.0893e-01,\n",
      "          5.5329e-01,  7.2679e-01, -5.2587e-01, -2.3170e-01,  7.3794e-01,\n",
      "         -1.1802e-01, -2.7479e-01, -1.7314e-02, -1.6327e-01, -3.4102e-02,\n",
      "          2.3925e-02,  2.9824e-01,  3.3681e-01, -2.5858e-01, -6.8072e-01,\n",
      "          4.3255e-01, -5.1592e-02,  1.3268e-01,  1.0031e+00, -4.9392e-01,\n",
      "         -3.4591e-01, -1.1116e+00,  1.0395e-01,  1.5350e-01,  1.9490e-01,\n",
      "         -3.1365e-01, -1.0147e-02,  1.2379e-01, -5.0719e-01, -1.7218e-01,\n",
      "         -1.4062e-01,  3.1903e-01,  2.5043e-01,  2.1692e-01,  5.1852e-01,\n",
      "          3.6862e-01,  4.0334e-01, -1.4356e-03, -8.7503e-02,  3.6795e-01,\n",
      "          4.3995e-01, -5.0485e-01, -1.1957e-01,  5.7448e-01, -3.9570e-01,\n",
      "         -1.3369e-01, -2.5921e-01, -2.3568e-01,  6.4013e-01,  4.0636e-01,\n",
      "         -2.2172e-02, -4.5787e-01, -1.2565e-01],\n",
      "        [-6.0734e-01, -3.1859e-02, -4.6142e-02, -2.6509e-01, -1.5293e-01,\n",
      "         -2.6509e-01, -5.3264e-01,  5.6901e-02,  9.0033e-02,  8.1175e-01,\n",
      "          4.4941e-01, -8.3102e-02, -8.4125e-01, -3.7634e-01, -1.4129e-01,\n",
      "          8.6609e-01, -3.9573e-01, -2.5183e-01,  7.1376e-01, -4.8350e-01,\n",
      "         -3.9823e-01, -1.9147e-01, -4.2489e-01, -1.2144e+00, -2.4627e-01,\n",
      "          7.2673e-01,  1.0897e+00, -4.4351e-02, -9.6108e-02, -7.4827e-01,\n",
      "         -3.1877e-01, -1.2178e-01, -4.4417e-01,  2.3191e-02, -4.9128e-01,\n",
      "          1.5643e-01, -3.3619e-01,  3.9600e-01, -5.8676e-01,  2.2154e-01,\n",
      "         -6.1522e-01, -6.0738e-02, -5.7063e-01, -6.7227e-01,  5.9067e-01,\n",
      "          5.0324e-01,  3.3801e-01, -6.2793e-01, -2.1499e-01, -1.4893e-02,\n",
      "         -3.8170e-01, -9.5663e-02,  4.7830e-01,  9.3440e-02,  9.4022e-01,\n",
      "          6.2101e-01,  1.5136e-01, -5.4739e-01, -2.0733e-01, -3.9109e-01,\n",
      "         -7.6287e-01, -1.4196e-01, -3.9886e-01, -4.9463e-01, -5.6923e-01,\n",
      "          2.6307e-01, -5.3431e-01, -1.1564e+00,  9.1909e-01,  6.8025e-01,\n",
      "         -5.2357e-01,  6.1507e-02,  8.4665e-01, -8.0633e-02,  7.9676e-01,\n",
      "          4.3386e-01,  7.6647e-01, -6.7767e-01, -2.4195e-01,  9.5379e-01,\n",
      "         -1.0931e-01, -4.1055e-01,  8.6217e-02, -1.6517e-01, -1.6167e-01,\n",
      "          1.3376e-01,  2.9284e-01,  4.0328e-01, -7.1462e-01, -9.4040e-01,\n",
      "          7.7058e-01, -2.9279e-01,  1.5088e-01,  1.3488e+00, -5.9095e-01,\n",
      "         -1.2540e-01, -1.4980e+00,  2.9010e-01,  2.7262e-01,  2.1946e-01,\n",
      "         -3.9451e-01, -5.7630e-02,  1.9183e-01, -3.8559e-01, -3.3813e-01,\n",
      "         -1.4339e-01,  2.6303e-01,  4.5689e-01,  7.1010e-01,  4.1381e-01,\n",
      "          3.6164e-01,  3.6812e-01, -7.6000e-02,  1.0005e-01,  4.8010e-01,\n",
      "          8.2668e-01, -2.8252e-01,  1.0808e-01,  9.9835e-01, -6.1348e-01,\n",
      "         -4.1229e-01, -7.4186e-02, -2.0359e-01,  9.8345e-01,  6.2847e-01,\n",
      "          1.0641e-01, -5.5179e-01, -3.6432e-01],\n",
      "        [-4.5920e-02,  4.6902e-01, -4.7171e-02,  2.2992e-01,  9.8004e-02,\n",
      "          1.9983e-01, -1.8645e-01, -2.2085e-02, -1.1275e-01,  3.8555e-01,\n",
      "          4.1014e-01,  3.8472e-01, -5.5607e-01, -5.2908e-03, -5.7391e-02,\n",
      "          6.8506e-01, -3.4721e-01, -2.5541e-01,  4.4044e-01, -4.7691e-01,\n",
      "         -5.7713e-02, -9.8066e-02, -1.5679e-01, -4.3847e-01, -3.3121e-01,\n",
      "          2.9152e-01,  7.7546e-01, -2.5095e-01, -8.8463e-02, -1.7717e-01,\n",
      "         -5.5704e-02, -2.7578e-01, -5.6644e-01,  3.7376e-03, -4.4851e-01,\n",
      "         -1.0373e-02, -3.0810e-01,  1.2433e-01, -2.4701e-01, -1.0382e-01,\n",
      "         -4.2696e-01,  1.6760e-01, -6.7383e-01, -1.6494e-01,  3.2512e-01,\n",
      "          2.0874e-01,  6.2372e-02, -3.3064e-02, -1.3027e-01,  1.7929e-01,\n",
      "          3.8406e-02,  3.3771e-01, -1.1248e-02, -3.0985e-02,  3.5640e-01,\n",
      "          6.1371e-01,  2.2983e-01, -5.2386e-01,  4.5964e-01,  7.8199e-04,\n",
      "         -4.6455e-01, -6.6622e-02,  1.2432e-01, -3.1792e-01, -1.2470e-01,\n",
      "          3.7811e-01, -3.1838e-01, -4.6196e-01,  5.8337e-01,  3.9086e-01,\n",
      "         -5.1992e-01, -5.7303e-02,  6.4416e-01,  3.1815e-02,  5.3225e-01,\n",
      "          3.7321e-01,  4.5959e-01, -3.6271e-01, -8.3378e-02,  4.7598e-01,\n",
      "          5.4750e-03, -3.6208e-01,  6.6018e-02, -4.0038e-01, -6.3853e-02,\n",
      "          2.2209e-01,  2.9927e-01,  2.4684e-01, -2.6462e-01, -4.9997e-01,\n",
      "          1.1177e-01,  4.2054e-01,  3.6050e-01,  9.3574e-01, -4.8638e-01,\n",
      "         -1.5737e-01, -7.9678e-01,  4.3225e-01, -4.4929e-02,  2.8773e-01,\n",
      "         -1.8422e-01, -6.8832e-02,  6.3630e-02, -3.2271e-01, -7.7737e-02,\n",
      "          1.9100e-01, -2.0256e-01,  7.7748e-02,  3.2813e-01,  3.9263e-01,\n",
      "          4.5866e-01,  1.2046e-01,  3.3303e-01, -2.8000e-01, -1.2052e-01,\n",
      "          1.6434e-01, -2.7992e-01, -2.6826e-01,  4.8130e-01, -4.3874e-01,\n",
      "         -1.2664e-01, -5.5164e-02, -1.2016e-01,  4.9414e-01,  5.9865e-02,\n",
      "         -9.9170e-02, -8.6036e-02,  1.8505e-01],\n",
      "        [-3.2025e-01,  3.0700e-01, -2.2527e-01,  3.8523e-02,  8.9623e-02,\n",
      "         -1.8770e-02, -2.9408e-01, -4.4318e-02,  1.3711e-01,  5.8156e-01,\n",
      "          5.3996e-01,  5.3510e-01, -3.2076e-01,  1.7185e-01,  1.0681e-01,\n",
      "          4.0519e-01, -4.6023e-01, -2.6535e-01,  4.9147e-01, -2.9980e-01,\n",
      "         -1.5934e-01, -2.2261e-01, -2.7712e-01, -7.2982e-01, -1.1778e-01,\n",
      "          6.1634e-01,  6.5136e-01, -3.4761e-02, -3.7044e-02, -3.7718e-01,\n",
      "         -1.6544e-01, -5.1307e-02, -6.8627e-01, -1.0234e-01, -1.9515e-01,\n",
      "         -3.0221e-01, -1.4957e-01,  2.9833e-01, -2.9500e-01,  7.9055e-03,\n",
      "         -3.8199e-01,  2.5399e-01, -4.4247e-01, -4.3359e-01,  2.4230e-01,\n",
      "          4.7520e-01,  2.5631e-01,  1.1655e-01, -1.0076e-01,  7.3190e-02,\n",
      "          4.5676e-01,  1.1716e-01,  2.8277e-01, -1.1736e-01,  8.8513e-01,\n",
      "          5.0058e-01,  3.8076e-02, -3.1291e-01,  3.7454e-01, -1.1318e-01,\n",
      "         -5.6383e-01,  1.8913e-01,  2.1057e-01, -1.2565e-01, -4.2564e-01,\n",
      "          5.0812e-01, -2.3623e-01, -6.1729e-01,  3.7533e-01,  4.0949e-01,\n",
      "         -4.2311e-01,  1.2544e-02,  4.8298e-01, -3.6304e-02,  5.8752e-01,\n",
      "          4.2494e-01,  1.7927e-01, -4.4654e-01,  1.5417e-01,  3.7141e-01,\n",
      "         -4.9196e-02, -4.9727e-01,  1.6459e-01, -1.6640e-01, -1.3378e-01,\n",
      "          2.6701e-01,  4.7230e-01,  2.9745e-01, -5.0257e-01, -6.9274e-01,\n",
      "          4.8864e-01,  9.6030e-02,  1.9741e-01,  1.1864e+00, -5.2566e-01,\n",
      "          5.2496e-02, -9.7840e-01,  8.5602e-01,  5.0011e-02,  2.7501e-01,\n",
      "         -2.0878e-01, -1.1657e-01,  1.3068e-01, -4.4548e-01, -2.7171e-01,\n",
      "          9.7974e-02, -1.3613e-01,  1.4630e-01,  6.5343e-01,  3.9534e-01,\n",
      "          3.0611e-01,  1.0157e-01,  3.2320e-01,  2.9315e-02, -1.5428e-01,\n",
      "          6.5336e-02, -2.3520e-01, -3.1047e-01,  7.7157e-01, -3.1474e-01,\n",
      "          7.0005e-03,  1.6710e-01,  6.6585e-02,  4.4274e-01,  8.2066e-02,\n",
      "          6.3831e-02,  1.1583e-01, -1.6313e-01]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e88c86-5d37-4f54-847a-d28f30a9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#带参数的层\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050e50c3-4cc5-45b4-805e-2ac309d93a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7419,  0.6114, -0.7210],\n",
       "        [ 0.0039,  0.6798,  0.2161],\n",
       "        [ 0.2227, -0.1355, -0.3872],\n",
       "        [ 1.6856, -0.5992, -0.9612],\n",
       "        [ 1.2005,  0.1124,  0.7317]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4de8d1-894a-4f0e-b322-fab086f42613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
